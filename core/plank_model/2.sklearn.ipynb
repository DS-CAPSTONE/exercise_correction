{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T04:30:09.620177Z",
     "start_time": "2024-10-08T04:30:08.943980Z"
    }
   },
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import precision_score, accuracy_score, f1_score, recall_score, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Drawing helpers\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Describe data and split dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T04:30:16.226461Z",
     "start_time": "2024-10-08T04:30:16.222726Z"
    }
   },
   "source": [
    "def rescale_frame(frame, percent=50):\n",
    "    '''\n",
    "    Rescale a frame to a certain percentage compare to its original frame\n",
    "    '''\n",
    "    width = int(frame.shape[1] * percent/ 100)\n",
    "    height = int(frame.shape[0] * percent/ 100)\n",
    "    dim = (width, height)\n",
    "    return cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "def describe_dataset(dataset_path: str):\n",
    "    '''\n",
    "    Describe dataset\n",
    "    '''\n",
    "\n",
    "    data = pd.read_csv(dataset_path)\n",
    "    print(f\"Headers: {list(data.columns.values)}\")\n",
    "    print(f'Number of rows: {data.shape[0]} \\nNumber of columns: {data.shape[1]}\\n')\n",
    "    print(f\"Labels: \\n{data['label'].value_counts()}\\n\")\n",
    "    print(f\"Missing values: {data.isnull().values.any()}\\n\")\n",
    "    \n",
    "    duplicate = data[data.duplicated()]\n",
    "    print(f\"Duplicate Rows : {len(duplicate.sum(axis=1))}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def round_up_metric_results(results) -> list:\n",
    "    '''Round up metrics results such as precision score, recall score, ...'''\n",
    "    return list(map(lambda el: round(el, 3), results))"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T04:31:17.604891Z",
     "start_time": "2024-10-08T04:31:17.253755Z"
    }
   },
   "source": [
    "df = describe_dataset(\"./train.csv\")\n",
    "df = pd.read_csv(\"./train.csv\")\n",
    "df.loc[df[\"label\"] == \"C\", \"label\"] = 0\n",
    "df.loc[df[\"label\"] == \"H\", \"label\"] = 1\n",
    "df.loc[df[\"label\"] == \"L\", \"label\"] = 2\n",
    "df.tail(3)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headers: ['label', 'nose_x', 'nose_y', 'nose_z', 'nose_v', 'left_shoulder_x', 'left_shoulder_y', 'left_shoulder_z', 'left_shoulder_v', 'right_shoulder_x', 'right_shoulder_y', 'right_shoulder_z', 'right_shoulder_v', 'left_elbow_x', 'left_elbow_y', 'left_elbow_z', 'left_elbow_v', 'right_elbow_x', 'right_elbow_y', 'right_elbow_z', 'right_elbow_v', 'left_wrist_x', 'left_wrist_y', 'left_wrist_z', 'left_wrist_v', 'right_wrist_x', 'right_wrist_y', 'right_wrist_z', 'right_wrist_v', 'left_hip_x', 'left_hip_y', 'left_hip_z', 'left_hip_v', 'right_hip_x', 'right_hip_y', 'right_hip_z', 'right_hip_v', 'left_knee_x', 'left_knee_y', 'left_knee_z', 'left_knee_v', 'right_knee_x', 'right_knee_y', 'right_knee_z', 'right_knee_v', 'left_ankle_x', 'left_ankle_y', 'left_ankle_z', 'left_ankle_v', 'right_ankle_x', 'right_ankle_y', 'right_ankle_z', 'right_ankle_v', 'left_heel_x', 'left_heel_y', 'left_heel_z', 'left_heel_v', 'right_heel_x', 'right_heel_y', 'right_heel_z', 'right_heel_v', 'left_foot_index_x', 'left_foot_index_y', 'left_foot_index_z', 'left_foot_index_v', 'right_foot_index_x', 'right_foot_index_y', 'right_foot_index_z', 'right_foot_index_v']\n",
      "Number of rows: 28520 \n",
      "Number of columns: 69\n",
      "\n",
      "Labels: \n",
      "C    9904\n",
      "L    9546\n",
      "H    9070\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Missing values: False\n",
      "\n",
      "Duplicate Rows : 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      label    nose_x    nose_y    nose_z    nose_v  left_shoulder_x  \\\n",
       "28517     1  0.735630  0.543294  0.007467  0.999246         0.695831   \n",
       "28518     1  0.775572  0.517579  0.012821  0.999378         0.704168   \n",
       "28519     1  0.790600  0.498958  0.007789  0.999467         0.710651   \n",
       "\n",
       "       left_shoulder_y  left_shoulder_z  left_shoulder_v  right_shoulder_x  \\\n",
       "28517         0.417349         0.155194         0.995723          0.720067   \n",
       "28518         0.404210         0.162908         0.995909          0.730823   \n",
       "28519         0.394019         0.164441         0.996123          0.736771   \n",
       "\n",
       "       ...  right_heel_z  right_heel_v  left_foot_index_x  left_foot_index_y  \\\n",
       "28517  ...      0.086010      0.966131           0.226601           0.598075   \n",
       "28518  ...      0.070911      0.967070           0.238810           0.610591   \n",
       "28519  ...      0.085872      0.967943           0.238197           0.609329   \n",
       "\n",
       "       left_foot_index_z  left_foot_index_v  right_foot_index_x  \\\n",
       "28517           0.219305           0.470830            0.220079   \n",
       "28518           0.198591           0.496140            0.228907   \n",
       "28519           0.233198           0.510583            0.227823   \n",
       "\n",
       "       right_foot_index_y  right_foot_index_z  right_foot_index_v  \n",
       "28517            0.614120            0.026265            0.934942  \n",
       "28518            0.625559            0.018591            0.938905  \n",
       "28519            0.626068            0.036127            0.940917  \n",
       "\n",
       "[3 rows x 69 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>nose_x</th>\n",
       "      <th>nose_y</th>\n",
       "      <th>nose_z</th>\n",
       "      <th>nose_v</th>\n",
       "      <th>left_shoulder_x</th>\n",
       "      <th>left_shoulder_y</th>\n",
       "      <th>left_shoulder_z</th>\n",
       "      <th>left_shoulder_v</th>\n",
       "      <th>right_shoulder_x</th>\n",
       "      <th>...</th>\n",
       "      <th>right_heel_z</th>\n",
       "      <th>right_heel_v</th>\n",
       "      <th>left_foot_index_x</th>\n",
       "      <th>left_foot_index_y</th>\n",
       "      <th>left_foot_index_z</th>\n",
       "      <th>left_foot_index_v</th>\n",
       "      <th>right_foot_index_x</th>\n",
       "      <th>right_foot_index_y</th>\n",
       "      <th>right_foot_index_z</th>\n",
       "      <th>right_foot_index_v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28517</th>\n",
       "      <td>1</td>\n",
       "      <td>0.735630</td>\n",
       "      <td>0.543294</td>\n",
       "      <td>0.007467</td>\n",
       "      <td>0.999246</td>\n",
       "      <td>0.695831</td>\n",
       "      <td>0.417349</td>\n",
       "      <td>0.155194</td>\n",
       "      <td>0.995723</td>\n",
       "      <td>0.720067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086010</td>\n",
       "      <td>0.966131</td>\n",
       "      <td>0.226601</td>\n",
       "      <td>0.598075</td>\n",
       "      <td>0.219305</td>\n",
       "      <td>0.470830</td>\n",
       "      <td>0.220079</td>\n",
       "      <td>0.614120</td>\n",
       "      <td>0.026265</td>\n",
       "      <td>0.934942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28518</th>\n",
       "      <td>1</td>\n",
       "      <td>0.775572</td>\n",
       "      <td>0.517579</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.999378</td>\n",
       "      <td>0.704168</td>\n",
       "      <td>0.404210</td>\n",
       "      <td>0.162908</td>\n",
       "      <td>0.995909</td>\n",
       "      <td>0.730823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070911</td>\n",
       "      <td>0.967070</td>\n",
       "      <td>0.238810</td>\n",
       "      <td>0.610591</td>\n",
       "      <td>0.198591</td>\n",
       "      <td>0.496140</td>\n",
       "      <td>0.228907</td>\n",
       "      <td>0.625559</td>\n",
       "      <td>0.018591</td>\n",
       "      <td>0.938905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28519</th>\n",
       "      <td>1</td>\n",
       "      <td>0.790600</td>\n",
       "      <td>0.498958</td>\n",
       "      <td>0.007789</td>\n",
       "      <td>0.999467</td>\n",
       "      <td>0.710651</td>\n",
       "      <td>0.394019</td>\n",
       "      <td>0.164441</td>\n",
       "      <td>0.996123</td>\n",
       "      <td>0.736771</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085872</td>\n",
       "      <td>0.967943</td>\n",
       "      <td>0.238197</td>\n",
       "      <td>0.609329</td>\n",
       "      <td>0.233198</td>\n",
       "      <td>0.510583</td>\n",
       "      <td>0.227823</td>\n",
       "      <td>0.626068</td>\n",
       "      <td>0.036127</td>\n",
       "      <td>0.940917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 69 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# Given the angle and the postions of the body parts, we need to predict the lables. "
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T04:33:17.992927Z",
     "start_time": "2024-10-08T04:33:17.990928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# - Correct: \"C\"\n",
    "# - Back is too low: \"L\"\n",
    "# - Back is too high: \"H\""
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T04:33:45.121112Z",
     "start_time": "2024-10-08T04:33:45.116089Z"
    }
   },
   "source": [
    "# Extract features and class\n",
    "X = df.drop(\"label\", axis=1) # features\n",
    "y = df[\"label\"].astype(\"int\") # TArget \n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T04:34:17.760629Z",
     "start_time": "2024-10-08T04:34:17.740781Z"
    }
   },
   "source": [
    "# Scale the features using standard scalar using the mean and standard deviations. \n",
    "\n",
    "sc = StandardScaler()\n",
    "X = pd.DataFrame(sc.fit_transform(X))"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T04:34:25.250572Z",
     "start_time": "2024-10-08T04:34:25.241893Z"
    }
   },
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "y_test.head(3)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20523    2\n",
       "3589     0\n",
       "8501     2\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Train model using Scikit-Learn and train set evaluation"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T04:44:28.676168Z",
     "start_time": "2024-10-08T04:42:18.498768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use the grid search to get the optimum hyperparameters \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Example parameter grids for each model\n",
    "param_grids = {\n",
    "    \"LR\": {'C': [0.01, 0.1, 1, 10]},\n",
    "    \"SVC\": {'C': [0.01, 0.1, 1], 'kernel': ['linear', 'rbf']},\n",
    "    \"KNN\": {'n_neighbors': [3, 5, 7, 9]},\n",
    "    \"DTC\": {'max_depth': [3, 5, 10], 'min_samples_split': [2, 5]},\n",
    "    \"SGDC\": {},\n",
    "    \"NB\": {},  # No hyperparameters to tune for GaussianNB\n",
    "    \"RF\": {'n_estimators': [100, 200], 'max_depth': [None, 10, 20]}\n",
    "}\n",
    "\n",
    "# Perform grid search on all algorithms\n",
    "best_models = {}\n",
    "\n",
    "algorithms =[(\"LR\", LogisticRegression()),\n",
    "         (\"SVC\", SVC(probability=True)),\n",
    "         ('KNN',KNeighborsClassifier()),\n",
    "         (\"DTC\", DecisionTreeClassifier()),\n",
    "         (\"SGDC\", CalibratedClassifierCV(SGDClassifier())),\n",
    "         (\"NB\", GaussianNB()),\n",
    "         ('RF', RandomForestClassifier()),]\n",
    "\n",
    "for name, model in algorithms:\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grids.get(name, {}), scoring='accuracy', cv=5, n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    best_models[name] = grid.best_estimator_\n",
    "    print(f\"Best parameters for {name}: {grid.best_params_}\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jainilpatel/PycharmProjects/Exercise-Correction/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jainilpatel/PycharmProjects/Exercise-Correction/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jainilpatel/PycharmProjects/Exercise-Correction/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jainilpatel/PycharmProjects/Exercise-Correction/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jainilpatel/PycharmProjects/Exercise-Correction/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jainilpatel/PycharmProjects/Exercise-Correction/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jainilpatel/PycharmProjects/Exercise-Correction/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jainilpatel/PycharmProjects/Exercise-Correction/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jainilpatel/PycharmProjects/Exercise-Correction/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jainilpatel/PycharmProjects/Exercise-Correction/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jainilpatel/PycharmProjects/Exercise-Correction/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jainilpatel/PycharmProjects/Exercise-Correction/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jainilpatel/PycharmProjects/Exercise-Correction/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jainilpatel/PycharmProjects/Exercise-Correction/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jainilpatel/PycharmProjects/Exercise-Correction/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for LR: {'C': 10}\n",
      "Best parameters for SVC: {'C': 1, 'kernel': 'linear'}\n",
      "Best parameters for KNN: {'n_neighbors': 3}\n",
      "Best parameters for DTC: {'max_depth': 10, 'min_samples_split': 2}\n",
      "Best parameters for SGDC: {}\n",
      "Best parameters for NB: {}\n",
      "Best parameters for RF: {'max_depth': None, 'n_estimators': 100}\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T04:45:08.259283Z",
     "start_time": "2024-10-08T04:44:53.523878Z"
    }
   },
   "source": [
    "algorithms =[(\"LR\", LogisticRegression(C=10)),\n",
    "         (\"SVC\", SVC(probability=True)),\n",
    "         ('KNN',KNeighborsClassifier(n_neighbors=3)),\n",
    "         (\"DTC\", DecisionTreeClassifier(max_depth=10, min_samples_split=5)),\n",
    "         (\"SGDC\", CalibratedClassifierCV(SGDClassifier())),\n",
    "         (\"NB\", GaussianNB()),\n",
    "         ('RF', RandomForestClassifier(max_depth=None, n_estimators=100)),]\n",
    "\n",
    "# once we have seen the algorithms hyperparameters, from the grid search we can see their performance. \n",
    "\n",
    "models = {}\n",
    "final_results = []\n",
    "\n",
    "for name, model in algorithms:\n",
    "    trained_model = model.fit(X_train, y_train)\n",
    "    models[name] = trained_model\n",
    "\n",
    "    # Evaluate model\n",
    "    model_results = model.predict(X_test)\n",
    "\n",
    "    p_score = precision_score(y_test, model_results, average=None, labels=[0, 1, 2])\n",
    "    a_score = accuracy_score(y_test, model_results)\n",
    "    r_score = recall_score(y_test, model_results, average=None, labels=[0, 1, 2])\n",
    "    f1_score_result = f1_score(y_test, model_results, average=None, labels=[0, 1, 2])\n",
    "    cm = confusion_matrix(y_test, model_results, labels=[0, 1, 2])\n",
    "    final_results.append(( name,  round_up_metric_results(p_score), a_score, round_up_metric_results(r_score), round_up_metric_results(f1_score_result), cm))\n"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T04:46:52.688360Z",
     "start_time": "2024-10-08T04:46:52.673651Z"
    }
   },
   "source": [
    "# Sort results by F1 score\n",
    "final_results.sort(key=lambda k: sum(k[4]), reverse=True)\n",
    "\n",
    "pd.DataFrame(final_results, columns=[\"Model\", \"Precision Score\", \"Accuracy score\", \"Recall Score\", \"F1 score\", \"Confusion Matrix\"])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  Model        Precision Score  Accuracy score           Recall Score  \\\n",
       "0    LR      [1.0, 1.0, 0.999]        0.999825      [0.999, 1.0, 1.0]   \n",
       "1   KNN      [0.999, 1.0, 1.0]        0.999649    [1.0, 0.999, 0.999]   \n",
       "2   SVC    [0.999, 1.0, 0.999]        0.999474  [0.999, 0.999, 0.999]   \n",
       "3    RF      [0.999, 1.0, 1.0]        0.999649      [1.0, 1.0, 0.999]   \n",
       "4   DTC  [0.996, 0.999, 0.997]        0.997546  [0.997, 0.998, 0.997]   \n",
       "5  SGDC  [0.997, 0.996, 0.998]        0.997195  [0.994, 0.999, 0.998]   \n",
       "6    NB  [0.815, 0.923, 0.943]        0.888499   [0.882, 0.959, 0.83]   \n",
       "\n",
       "                F1 score                                  Confusion Matrix  \n",
       "0        [1.0, 1.0, 1.0]        [[1984, 0, 1], [0, 1788, 0], [0, 0, 1931]]  \n",
       "1      [0.999, 1.0, 1.0]        [[1985, 0, 0], [1, 1787, 0], [1, 0, 1930]]  \n",
       "2    [0.999, 1.0, 0.999]        [[1984, 0, 1], [1, 1787, 0], [1, 0, 1930]]  \n",
       "3    [0.999, 1.0, 0.999]        [[1985, 0, 0], [0, 1788, 0], [2, 0, 1929]]  \n",
       "4  [0.997, 0.999, 0.997]        [[1980, 1, 4], [3, 1784, 1], [5, 0, 1926]]  \n",
       "5  [0.996, 0.998, 0.998]        [[1974, 7, 4], [1, 1787, 0], [4, 0, 1927]]  \n",
       "6  [0.847, 0.941, 0.883]  [[1750, 139, 96], [73, 1715, 0], [324, 4, 1603]]  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision Score</th>\n",
       "      <th>Accuracy score</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>[1.0, 1.0, 0.999]</td>\n",
       "      <td>0.999825</td>\n",
       "      <td>[0.999, 1.0, 1.0]</td>\n",
       "      <td>[1.0, 1.0, 1.0]</td>\n",
       "      <td>[[1984, 0, 1], [0, 1788, 0], [0, 0, 1931]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>[0.999, 1.0, 1.0]</td>\n",
       "      <td>0.999649</td>\n",
       "      <td>[1.0, 0.999, 0.999]</td>\n",
       "      <td>[0.999, 1.0, 1.0]</td>\n",
       "      <td>[[1985, 0, 0], [1, 1787, 0], [1, 0, 1930]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>[0.999, 1.0, 0.999]</td>\n",
       "      <td>0.999474</td>\n",
       "      <td>[0.999, 0.999, 0.999]</td>\n",
       "      <td>[0.999, 1.0, 0.999]</td>\n",
       "      <td>[[1984, 0, 1], [1, 1787, 0], [1, 0, 1930]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>[0.999, 1.0, 1.0]</td>\n",
       "      <td>0.999649</td>\n",
       "      <td>[1.0, 1.0, 0.999]</td>\n",
       "      <td>[0.999, 1.0, 0.999]</td>\n",
       "      <td>[[1985, 0, 0], [0, 1788, 0], [2, 0, 1929]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DTC</td>\n",
       "      <td>[0.996, 0.999, 0.997]</td>\n",
       "      <td>0.997546</td>\n",
       "      <td>[0.997, 0.998, 0.997]</td>\n",
       "      <td>[0.997, 0.999, 0.997]</td>\n",
       "      <td>[[1980, 1, 4], [3, 1784, 1], [5, 0, 1926]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SGDC</td>\n",
       "      <td>[0.997, 0.996, 0.998]</td>\n",
       "      <td>0.997195</td>\n",
       "      <td>[0.994, 0.999, 0.998]</td>\n",
       "      <td>[0.996, 0.998, 0.998]</td>\n",
       "      <td>[[1974, 7, 4], [1, 1787, 0], [4, 0, 1927]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NB</td>\n",
       "      <td>[0.815, 0.923, 0.943]</td>\n",
       "      <td>0.888499</td>\n",
       "      <td>[0.882, 0.959, 0.83]</td>\n",
       "      <td>[0.847, 0.941, 0.883]</td>\n",
       "      <td>[[1750, 139, 96], [73, 1715, 0], [324, 4, 1603]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T04:47:16.244958Z",
     "start_time": "2024-10-08T04:47:02.373679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# Create a list of (name, model) tuples from trained models\n",
    "voting_estimators = [(name, model) for name, model in models.items()]\n",
    "\n",
    "# Use VotingClassifier (soft voting averages the probabilities for each class)\n",
    "voting_clf = VotingClassifier(estimators=voting_estimators, voting='soft')  # For probability voting\n",
    "\n",
    "# Train the ensemble classifier\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the ensemble model\n",
    "ensemble_predictions = voting_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the ensemble model's performance\n",
    "ensemble_precision = precision_score(y_test, ensemble_predictions, average=None, labels=[0, 1, 2])\n",
    "ensemble_accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "ensemble_recall = recall_score(y_test, ensemble_predictions, average=None, labels=[0, 1, 2])\n",
    "ensemble_f1_score = f1_score(y_test, ensemble_predictions, average=None, labels=[0, 1, 2])\n",
    "ensemble_cm = confusion_matrix(y_test, ensemble_predictions, labels=[0, 1, 2])\n",
    "\n",
    "# Print results\n",
    "print(\"Ensemble Voting Classifier Results:\")\n",
    "print(f\"Precision: {ensemble_precision}\")\n",
    "print(f\"Accuracy: {ensemble_accuracy:.4f}\")\n",
    "print(f\"Recall: {ensemble_recall}\")\n",
    "print(f\"F1 Score: {ensemble_f1_score}\")\n",
    "print(f\"Confusion Matrix:\\n {ensemble_cm}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Voting Classifier Results:\n",
      "Precision: [0.99899295 1.         0.99948213]\n",
      "Accuracy: 0.9995\n",
      "Recall: [0.99949622 0.99944072 0.99948213]\n",
      "F1 Score: [0.99924452 0.99972028 0.99948213]\n",
      "Confusion Matrix:\n",
      " [[1984    0    1]\n",
      " [   1 1787    0]\n",
      " [   1    0 1930]]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Test set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T04:49:44.459793Z",
     "start_time": "2024-10-08T04:49:44.364764Z"
    }
   },
   "source": [
    "test_df = describe_dataset(\"./test.csv\")\n",
    "test_df = test_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "test_df.loc[test_df[\"label\"] == \"C\", \"label\"] = 0\n",
    "test_df.loc[test_df[\"label\"] == \"H\", \"label\"] = 1\n",
    "test_df.loc[test_df[\"label\"] == \"L\", \"label\"] = 2\n",
    "\n",
    "test_x = test_df.drop(\"label\", axis=1)\n",
    "test_y = test_df[\"label\"].astype(\"int\")\n",
    "\n",
    "test_x = pd.DataFrame(sc.transform(test_x))\n",
    "\n",
    "\n",
    "model_results = voting_clf.predict(test_x)\n",
    "\n",
    "p_score = precision_score(test_y, model_results, average=None, labels=[0, 1, 2])\n",
    "a_score = accuracy_score(test_y, model_results)\n",
    "r_score = recall_score(test_y, model_results, average=None, labels=[0, 1, 2])\n",
    "f1_score_result = f1_score(test_y, model_results, average=None, labels=[0, 1, 2])\n",
    "cm = confusion_matrix(test_y, model_results, labels=[0, 1, 2])\n",
    "\n",
    "testset_final_results = []\n",
    "\n",
    "testset_final_results.append(( \"VOTER\",  round_up_metric_results(p_score), a_score, round_up_metric_results(r_score), round_up_metric_results(f1_score_result), cm ))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headers: ['label', 'nose_x', 'nose_y', 'nose_z', 'nose_v', 'left_shoulder_x', 'left_shoulder_y', 'left_shoulder_z', 'left_shoulder_v', 'right_shoulder_x', 'right_shoulder_y', 'right_shoulder_z', 'right_shoulder_v', 'left_elbow_x', 'left_elbow_y', 'left_elbow_z', 'left_elbow_v', 'right_elbow_x', 'right_elbow_y', 'right_elbow_z', 'right_elbow_v', 'left_wrist_x', 'left_wrist_y', 'left_wrist_z', 'left_wrist_v', 'right_wrist_x', 'right_wrist_y', 'right_wrist_z', 'right_wrist_v', 'left_hip_x', 'left_hip_y', 'left_hip_z', 'left_hip_v', 'right_hip_x', 'right_hip_y', 'right_hip_z', 'right_hip_v', 'left_knee_x', 'left_knee_y', 'left_knee_z', 'left_knee_v', 'right_knee_x', 'right_knee_y', 'right_knee_z', 'right_knee_v', 'left_ankle_x', 'left_ankle_y', 'left_ankle_z', 'left_ankle_v', 'right_ankle_x', 'right_ankle_y', 'right_ankle_z', 'right_ankle_v', 'left_heel_x', 'left_heel_y', 'left_heel_z', 'left_heel_v', 'right_heel_x', 'right_heel_y', 'right_heel_z', 'right_heel_v', 'left_foot_index_x', 'left_foot_index_y', 'left_foot_index_z', 'left_foot_index_v', 'right_foot_index_x', 'right_foot_index_y', 'right_foot_index_z', 'right_foot_index_v']\n",
      "Number of rows: 710 \n",
      "Number of columns: 69\n",
      "\n",
      "Labels: \n",
      "H    241\n",
      "L    235\n",
      "C    234\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Missing values: False\n",
      "\n",
      "Duplicate Rows : 0\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T04:49:50.095802Z",
     "start_time": "2024-10-08T04:49:50.092774Z"
    }
   },
   "cell_type": "code",
   "source": "testset_final_results",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('VOTER',\n",
       "  [0.979, 1.0, 0.996],\n",
       "  0.9915492957746479,\n",
       "  [1.0, 0.992, 0.983],\n",
       "  [0.989, 0.996, 0.989],\n",
       "  array([[234,   0,   0],\n",
       "         [  1, 239,   1],\n",
       "         [  4,   0, 231]]))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T04:50:21.171538Z",
     "start_time": "2024-10-08T04:50:21.141028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_df = describe_dataset(\"./test.csv\")\n",
    "test_df = test_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "test_df.loc[test_df[\"label\"] == \"C\", \"label\"] = 0\n",
    "test_df.loc[test_df[\"label\"] == \"H\", \"label\"] = 1\n",
    "test_df.loc[test_df[\"label\"] == \"L\", \"label\"] = 2\n",
    "\n",
    "test_x = test_df.drop(\"label\", axis=1)\n",
    "test_y = test_df[\"label\"].astype(\"int\")\n",
    "\n",
    "test_x = pd.DataFrame(sc.transform(test_x))\n",
    "\n",
    "\n",
    "model_results = model.predict(test_x)\n",
    "\n",
    "p_score = precision_score(test_y, model_results, average=None, labels=[0, 1, 2])\n",
    "a_score = accuracy_score(test_y, model_results)\n",
    "r_score = recall_score(test_y, model_results, average=None, labels=[0, 1, 2])\n",
    "f1_score_result = f1_score(test_y, model_results, average=None, labels=[0, 1, 2])\n",
    "cm = confusion_matrix(test_y, model_results, labels=[0, 1, 2])\n",
    "\n",
    "testset_final_results = []\n",
    "\n",
    "testset_final_results.append(( \"single model\",  round_up_metric_results(p_score), a_score, round_up_metric_results(r_score), round_up_metric_results(f1_score_result), cm ))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headers: ['label', 'nose_x', 'nose_y', 'nose_z', 'nose_v', 'left_shoulder_x', 'left_shoulder_y', 'left_shoulder_z', 'left_shoulder_v', 'right_shoulder_x', 'right_shoulder_y', 'right_shoulder_z', 'right_shoulder_v', 'left_elbow_x', 'left_elbow_y', 'left_elbow_z', 'left_elbow_v', 'right_elbow_x', 'right_elbow_y', 'right_elbow_z', 'right_elbow_v', 'left_wrist_x', 'left_wrist_y', 'left_wrist_z', 'left_wrist_v', 'right_wrist_x', 'right_wrist_y', 'right_wrist_z', 'right_wrist_v', 'left_hip_x', 'left_hip_y', 'left_hip_z', 'left_hip_v', 'right_hip_x', 'right_hip_y', 'right_hip_z', 'right_hip_v', 'left_knee_x', 'left_knee_y', 'left_knee_z', 'left_knee_v', 'right_knee_x', 'right_knee_y', 'right_knee_z', 'right_knee_v', 'left_ankle_x', 'left_ankle_y', 'left_ankle_z', 'left_ankle_v', 'right_ankle_x', 'right_ankle_y', 'right_ankle_z', 'right_ankle_v', 'left_heel_x', 'left_heel_y', 'left_heel_z', 'left_heel_v', 'right_heel_x', 'right_heel_y', 'right_heel_z', 'right_heel_v', 'left_foot_index_x', 'left_foot_index_y', 'left_foot_index_z', 'left_foot_index_v', 'right_foot_index_x', 'right_foot_index_y', 'right_foot_index_z', 'right_foot_index_v']\n",
      "Number of rows: 710 \n",
      "Number of columns: 69\n",
      "\n",
      "Labels: \n",
      "H    241\n",
      "L    235\n",
      "C    234\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Missing values: False\n",
      "\n",
      "Duplicate Rows : 0\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T04:50:34.724104Z",
     "start_time": "2024-10-08T04:50:34.721098Z"
    }
   },
   "cell_type": "code",
   "source": "testset_final_results",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('single model',\n",
       "  [0.701, 1.0, 1.0],\n",
       "  0.8591549295774648,\n",
       "  [1.0, 0.996, 0.579],\n",
       "  [0.824, 0.998, 0.733],\n",
       "  array([[234,   0,   0],\n",
       "         [  1, 240,   0],\n",
       "         [ 99,   0, 136]]))]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# We can see that the voter is performing very good. "
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4. Dumped model and input scaler using pickle\n",
    "\n",
    "According to the evaluations, there are multiple good models at the moment, therefore, the best models are LR and Ridge."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T04:50:41.207138Z",
     "start_time": "2024-10-08T04:50:41.196065Z"
    }
   },
   "source": [
    "with open(\"./model/all_sklearn_jainil.pkl\", \"wb\") as f:\n",
    "    pickle.dump(models, f)"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T04:50:41.427725Z",
     "start_time": "2024-10-08T04:50:41.424954Z"
    }
   },
   "source": [
    "with open(\"./model/LR_model_jainil.pkl\", \"wb\") as f:\n",
    "    pickle.dump(models[\"LR\"], f)"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T04:50:42.009433Z",
     "start_time": "2024-10-08T04:50:42.006662Z"
    }
   },
   "source": [
    "with open(\"./model/SVC_model_jainil.pkl\", \"wb\") as f:\n",
    "    pickle.dump(models[\"SVC\"], f)"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T04:50:42.537907Z",
     "start_time": "2024-10-08T04:50:42.535147Z"
    }
   },
   "source": [
    "# Dump input scaler\n",
    "with open(\"./model/input_scaler_jainil.pkl\", \"wb\") as f:\n",
    "    pickle.dump(sc, f)"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T04:51:04.046035Z",
     "start_time": "2024-10-08T04:51:04.033002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dump input scaler\n",
    "with open(\"./model/voter.pkl\", \"wb\") as f:\n",
    "    pickle.dump(voting_clf, f)"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9260f401923fb5c4108c543a7d176de9733d378b3752e49535ad7c43c2271b65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
