{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T03:24:32.056240Z",
     "start_time": "2024-09-12T03:24:31.395094Z"
    }
   },
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Drawing helpers\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[34933]: Class CaptureDelegate is implemented in both /Users/jainilpatel/PycharmProjects/Exercise-Correction/.venv/lib/python3.9/site-packages/mediapipe/.dylibs/libopencv_videoio.3.4.16.dylib (0x103f08860) and /Users/jainilpatel/PycharmProjects/Exercise-Correction/.venv/lib/python3.9/site-packages/cv2/cv2.abi3.so (0x30d476480). One of the two will be used. Which one is undefined.\n",
      "objc[34933]: Class CVWindow is implemented in both /Users/jainilpatel/PycharmProjects/Exercise-Correction/.venv/lib/python3.9/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x103c70a68) and /Users/jainilpatel/PycharmProjects/Exercise-Correction/.venv/lib/python3.9/site-packages/cv2/cv2.abi3.so (0x30d4764d0). One of the two will be used. Which one is undefined.\n",
      "objc[34933]: Class CVView is implemented in both /Users/jainilpatel/PycharmProjects/Exercise-Correction/.venv/lib/python3.9/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x103c70a90) and /Users/jainilpatel/PycharmProjects/Exercise-Correction/.venv/lib/python3.9/site-packages/cv2/cv2.abi3.so (0x30d4764f8). One of the two will be used. Which one is undefined.\n",
      "objc[34933]: Class CVSlider is implemented in both /Users/jainilpatel/PycharmProjects/Exercise-Correction/.venv/lib/python3.9/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x103c70ab8) and /Users/jainilpatel/PycharmProjects/Exercise-Correction/.venv/lib/python3.9/site-packages/cv2/cv2.abi3.so (0x30d476520). One of the two will be used. Which one is undefined.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Reconstruct input structure"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T03:24:35.505960Z",
     "start_time": "2024-09-12T03:24:35.503442Z"
    }
   },
   "source": [
    "# Determine important landmarks for lunge\n",
    "IMPORTANT_LMS = [\n",
    "    \"NOSE\",\n",
    "    \"LEFT_SHOULDER\",\n",
    "    \"RIGHT_SHOULDER\",\n",
    "    \"LEFT_HIP\",\n",
    "    \"RIGHT_HIP\",\n",
    "    \"LEFT_KNEE\",\n",
    "    \"RIGHT_KNEE\",\n",
    "    \"LEFT_ANKLE\",\n",
    "    \"RIGHT_ANKLE\",\n",
    "    \"LEFT_HEEL\",\n",
    "    \"RIGHT_HEEL\",\n",
    "    \"LEFT_FOOT_INDEX\",\n",
    "    \"RIGHT_FOOT_INDEX\",\n",
    "]\n",
    "\n",
    "# Generate all columns of the data frame\n",
    "\n",
    "HEADERS = [\"label\"] # Label column\n",
    "\n",
    "for lm in IMPORTANT_LMS:\n",
    "    HEADERS += [f\"{lm.lower()}_x\", f\"{lm.lower()}_y\", f\"{lm.lower()}_z\", f\"{lm.lower()}_v\"]"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Set up important functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T03:24:36.440382Z",
     "start_time": "2024-09-12T03:24:36.429899Z"
    }
   },
   "source": [
    "def extract_important_keypoints(results) -> list:\n",
    "    '''\n",
    "    Extract important keypoints from mediapipe pose detection\n",
    "    '''\n",
    "    landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "    data = []\n",
    "    for lm in IMPORTANT_LMS:\n",
    "        keypoint = landmarks[mp_pose.PoseLandmark[lm].value]\n",
    "        data.append([keypoint.x, keypoint.y, keypoint.z, keypoint.visibility])\n",
    "    \n",
    "    return np.array(data).flatten().tolist()\n",
    "\n",
    "\n",
    "def rescale_frame(frame, percent=50):\n",
    "    '''\n",
    "    Rescale a frame to a certain percentage compare to its original frame\n",
    "    '''\n",
    "    width = int(frame.shape[1] * percent/ 100)\n",
    "    height = int(frame.shape[0] * percent/ 100)\n",
    "    dim = (width, height)\n",
    "    return cv2.resize(frame, dim, interpolation =cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "def calculate_angle(point1: list, point2: list, point3: list) -> float:\n",
    "    '''\n",
    "    Calculate the angle between 3 points\n",
    "    Unit of the angle will be in Degree\n",
    "    '''\n",
    "    point1 = np.array(point1)\n",
    "    point2 = np.array(point2)\n",
    "    point3 = np.array(point3)\n",
    "\n",
    "    # Calculate algo\n",
    "    angleInRad = np.arctan2(point3[1] - point2[1], point3[0] - point2[0]) - np.arctan2(point1[1] - point2[1], point1[0] - point2[0])\n",
    "    angleInDeg = np.abs(angleInRad * 180.0 / np.pi)\n",
    "\n",
    "    angleInDeg = angleInDeg if angleInDeg <= 180 else 360 - angleInDeg\n",
    "    return angleInDeg\n",
    "    \n",
    "\n",
    "def analyze_knee_angle(\n",
    "    mp_results, stage: str, angle_thresholds: list, draw_to_image: tuple = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculate angle of each knee while performer at the DOWN position\n",
    "\n",
    "    Return result explanation:\n",
    "        error: True if at least 1 error\n",
    "        right\n",
    "            error: True if an error is on the right knee\n",
    "            angle: Right knee angle\n",
    "        left\n",
    "            error: True if an error is on the left knee\n",
    "            angle: Left knee angle\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        \"error\": None,\n",
    "        \"right\": {\"error\": None, \"angle\": None},\n",
    "        \"left\": {\"error\": None, \"angle\": None},\n",
    "    }\n",
    "\n",
    "    landmarks = mp_results.pose_landmarks.landmark\n",
    "\n",
    "    # Calculate right knee angle\n",
    "    right_hip = [\n",
    "        landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "        landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y,\n",
    "    ]\n",
    "    right_knee = [\n",
    "        landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,\n",
    "        landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y,\n",
    "    ]\n",
    "    right_ankle = [\n",
    "        landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,\n",
    "        landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y,\n",
    "    ]\n",
    "    results[\"right\"][\"angle\"] = calculate_angle(right_hip, right_knee, right_ankle)\n",
    "\n",
    "    # Calculate left knee angle\n",
    "    left_hip = [\n",
    "        landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "        landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y,\n",
    "    ]\n",
    "    left_knee = [\n",
    "        landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",
    "        landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y,\n",
    "    ]\n",
    "    left_ankle = [\n",
    "        landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n",
    "        landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y,\n",
    "    ]\n",
    "    results[\"left\"][\"angle\"] = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "\n",
    "    # Draw to image\n",
    "    if draw_to_image is not None and stage != \"down\":\n",
    "        (image, video_dimensions) = draw_to_image\n",
    "\n",
    "        # Visualize angles\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            str(int(results[\"right\"][\"angle\"])),\n",
    "            tuple(np.multiply(right_knee, video_dimensions).astype(int)),\n",
    "            cv2.FONT_HERSHEY_COMPLEX,\n",
    "            0.5,\n",
    "            (255, 255, 255),\n",
    "            1,\n",
    "            cv2.LINE_AA,\n",
    "        )\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            str(int(results[\"left\"][\"angle\"])),\n",
    "            tuple(np.multiply(left_knee, video_dimensions).astype(int)),\n",
    "            cv2.FONT_HERSHEY_COMPLEX,\n",
    "            0.5,\n",
    "            (255, 255, 255),\n",
    "            1,\n",
    "            cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "    if stage != \"down\":\n",
    "        return results\n",
    "\n",
    "    # Evaluation\n",
    "    results[\"error\"] = False\n",
    "\n",
    "    if angle_thresholds[0] <= results[\"right\"][\"angle\"] <= angle_thresholds[1]:\n",
    "        results[\"right\"][\"error\"] = False\n",
    "    else:\n",
    "        results[\"right\"][\"error\"] = True\n",
    "        results[\"error\"] = True\n",
    "\n",
    "    if angle_thresholds[0] <= results[\"left\"][\"angle\"] <= angle_thresholds[1]:\n",
    "        results[\"left\"][\"error\"] = False\n",
    "    else:\n",
    "        results[\"left\"][\"error\"] = True\n",
    "        results[\"error\"] = True\n",
    "\n",
    "    # Draw to image\n",
    "    if draw_to_image is not None:\n",
    "        (image, video_dimensions) = draw_to_image\n",
    "\n",
    "        right_color = (255, 255, 255) if not results[\"right\"][\"error\"] else (0, 0, 255)\n",
    "        left_color = (255, 255, 255) if not results[\"left\"][\"error\"] else (0, 0, 255)\n",
    "\n",
    "        right_font_scale = 0.5 if not results[\"right\"][\"error\"] else 1\n",
    "        left_font_scale = 0.5 if not results[\"left\"][\"error\"] else 1\n",
    "\n",
    "        right_thickness = 1 if not results[\"right\"][\"error\"] else 2\n",
    "        left_thickness = 1 if not results[\"left\"][\"error\"] else 2\n",
    "\n",
    "        # Visualize angles\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            str(int(results[\"right\"][\"angle\"])),\n",
    "            tuple(np.multiply(right_knee, video_dimensions).astype(int)),\n",
    "            cv2.FONT_HERSHEY_COMPLEX,\n",
    "            right_font_scale,\n",
    "            right_color,\n",
    "            right_thickness,\n",
    "            cv2.LINE_AA,\n",
    "        )\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            str(int(results[\"left\"][\"angle\"])),\n",
    "            tuple(np.multiply(left_knee, video_dimensions).astype(int)),\n",
    "            cv2.FONT_HERSHEY_COMPLEX,\n",
    "            left_font_scale,\n",
    "            left_color,\n",
    "            left_thickness,\n",
    "            cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T03:24:37.674754Z",
     "start_time": "2024-09-12T03:24:37.671676Z"
    }
   },
   "source": [
    "VIDEO_PATH1 = \"../../lunge_demo.mp4\"\n",
    "VIDEO_PATH1 = 0"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T03:24:42.489268Z",
     "start_time": "2024-09-12T03:24:42.057954Z"
    }
   },
   "source": [
    "with open(\"./model/input_scaler.pkl\", \"rb\") as f:\n",
    "    input_scaler = pickle.load(f)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Detection with Sklearn model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T03:18:20.992457Z",
     "start_time": "2024-09-12T03:18:20.986362Z"
    }
   },
   "source": [
    "# Load model\n",
    "with open(\"./model/sklearn/stage_KNN_model_jainil.pkl\", \"rb\") as f:\n",
    "    sklearn_model = pickle.load(f)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T03:21:02.728213Z",
     "start_time": "2024-09-12T03:18:52.276512Z"
    }
   },
   "source": [
    "cap = cv2.VideoCapture(VIDEO_PATH1)\n",
    "current_stage = \"\"\n",
    "counter = 0\n",
    "prediction_probability_threshold = 0.8\n",
    "ANGLE_THRESHOLDS = [60, 135]\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, image = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Reduce size of a frame\n",
    "        image = rescale_frame(image, 50)\n",
    "        video_dimensions = [image.shape[1], image.shape[0]]\n",
    "\n",
    "        # Recolor image from BGR to RGB for mediapipe\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        results = pose.process(image)\n",
    "\n",
    "        if not results.pose_landmarks:\n",
    "            print(\"No human found\")\n",
    "            continue\n",
    "\n",
    "        # Recolor image from BGR to RGB for mediapipe\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Draw landmarks and connections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS, mp_drawing.DrawingSpec(color=(244, 117, 66), thickness=2, circle_radius=2), mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=1))\n",
    "\n",
    "        # Make detection\n",
    "        try:\n",
    "            # Extract keypoints from frame for the input\n",
    "            row = extract_important_keypoints(results)\n",
    "            X = pd.DataFrame([row], columns=HEADERS[1:])\n",
    "            X = pd.DataFrame(input_scaler.transform(X))\n",
    "\n",
    "            # Make prediction and its probability\n",
    "            predicted_class = sklearn_model.predict(X)[0]\n",
    "            prediction_probabilities = sklearn_model.predict_proba(X)[0]\n",
    "            prediction_probability = round(prediction_probabilities[prediction_probabilities.argmax()], 2)\n",
    "\n",
    "            # Evaluate model prediction\n",
    "            if predicted_class == \"I\" and prediction_probability >= prediction_probability_threshold:\n",
    "                current_stage = \"init\"\n",
    "            elif predicted_class == \"M\" and prediction_probability >= prediction_probability_threshold: \n",
    "                current_stage = \"mid\"\n",
    "            elif predicted_class == \"D\" and prediction_probability >= prediction_probability_threshold:\n",
    "                if current_stage == \"mid\":\n",
    "                    counter += 1\n",
    "                \n",
    "                current_stage = \"down\"\n",
    "            \n",
    "            # Error detection\n",
    "            analyze_knee_angle(mp_results=results, stage=current_stage, angle_thresholds=ANGLE_THRESHOLDS, draw_to_image=(image, video_dimensions))\n",
    "            \n",
    "            # Visualization\n",
    "            # Status box\n",
    "            cv2.rectangle(image, (0, 0), (400, 60), (245, 117, 16), -1)\n",
    "\n",
    "             # Display probability\n",
    "            cv2.putText(image, \"PROB\", (15, 12), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(prediction_probability), (10, 40), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Display class\n",
    "            cv2.putText(image, \"CLASS\", (95, 12), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, current_stage, (90, 40), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Display probability\n",
    "            cv2.putText(image, \"COUNTER\", (255, 12), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(counter), (250, 40), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            traceback.print_exc()\n",
    "        \n",
    "        cv2.imshow(\"CV2\", image)\n",
    "        \n",
    "        # Press Q to close cv2 window\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # (Optional)Fix bugs cannot close windows in MacOS (https://stackoverflow.com/questions/6116564/destroywindow-does-not-close-window-on-mac-using-python-and-opencv)\n",
    "    for i in range (1, 5):\n",
    "        cv2.waitKey(1)\n",
    "  "
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 22:18:52.828 python[32961:24664375] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n",
      "No human found\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "Unknown C++ exception from OpenCV code",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31merror\u001B[0m                                     Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 84\u001B[0m\n\u001B[1;32m     81\u001B[0m     cv2\u001B[38;5;241m.\u001B[39mimshow(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCV2\u001B[39m\u001B[38;5;124m\"\u001B[39m, image)\n\u001B[1;32m     83\u001B[0m     \u001B[38;5;66;03m# Press Q to close cv2 window\u001B[39;00m\n\u001B[0;32m---> 84\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwaitKey\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;241m&\u001B[39m \u001B[38;5;241m0xFF\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mord\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mq\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m     85\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m     87\u001B[0m cap\u001B[38;5;241m.\u001B[39mrelease()\n",
      "\u001B[0;31merror\u001B[0m: Unknown C++ exception from OpenCV code"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Detection with Deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T03:24:51.244804Z",
     "start_time": "2024-09-12T03:24:48.293901Z"
    }
   },
   "source": [
    "# Load model\n",
    "with open(\"./model/dp/stage_lunge_dp.pkl\", \"rb\") as f:\n",
    "    deep_learning_model = pickle.load(f)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T03:25:22.612234Z",
     "start_time": "2024-09-12T03:24:52.182547Z"
    }
   },
   "source": [
    "cap = cv2.VideoCapture(VIDEO_PATH1)\n",
    "current_stage = \"\"\n",
    "counter = 0\n",
    "prediction_probability_threshold = 0.6\n",
    "ANGLE_THRESHOLDS = [60, 135]\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, image = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Reduce size of a frame\n",
    "        image = rescale_frame(image, 50)\n",
    "        image = cv2.flip(image, 1)\n",
    "        video_dimensions = [image.shape[1], image.shape[0]]\n",
    "\n",
    "        # Recolor image from BGR to RGB for mediapipe\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        results = pose.process(image)\n",
    "\n",
    "        if not results.pose_landmarks:\n",
    "            print(\"No human found\")\n",
    "            continue\n",
    "\n",
    "        # Recolor image from BGR to RGB for mediapipe\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Draw landmarks and connections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS, mp_drawing.DrawingSpec(color=(244, 117, 66), thickness=2, circle_radius=2), mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=1))\n",
    "\n",
    "        # Make detection\n",
    "        try:\n",
    "            # Extract keypoints from frame for the input\n",
    "            row = extract_important_keypoints(results)\n",
    "            X = pd.DataFrame([row, ], columns=HEADERS[1:])\n",
    "            X = pd.DataFrame(input_scaler.transform(X))\n",
    "            \n",
    "\n",
    "            # Make prediction and its probability\n",
    "            prediction = deep_learning_model.predict(X)\n",
    "            predicted_class = np.argmax(prediction, axis=1)[0]\n",
    "            prediction_probability = max(prediction.tolist()[0])\n",
    "\n",
    "            # Evaluate model prediction\n",
    "            if predicted_class == 0 and prediction_probability >= prediction_probability_threshold:\n",
    "                current_stage = \"init\"\n",
    "            elif predicted_class == 1 and prediction_probability >= prediction_probability_threshold: \n",
    "                current_stage = \"mid\"\n",
    "            elif predicted_class == 2 and prediction_probability >= prediction_probability_threshold:\n",
    "                if current_stage == \"mid\":\n",
    "                    counter += 1\n",
    "\n",
    "                current_stage = \"down\"\n",
    "            \n",
    "            analyze_knee_angle(mp_results=results, stage=current_stage, angle_thresholds=ANGLE_THRESHOLDS, draw_to_image=(image, video_dimensions))\n",
    "\n",
    "            # Visualization\n",
    "            # Status box\n",
    "            cv2.rectangle(image, (0, 0), (550, 60), (245, 117, 16), -1)\n",
    "\n",
    "            # # Display class\n",
    "            cv2.putText(image, \"DETECTION\", (95, 12), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, current_stage, (90, 40), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # # Display probability\n",
    "            cv2.putText(image, \"PROB\", (15, 12), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(round(prediction_probability, 2)), (10, 40), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # # Display class\n",
    "            cv2.putText(image, \"CLASS\", (225, 12), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(predicted_class), (220, 40), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # # Display class\n",
    "            cv2.putText(image, \"COUNTER\", (350, 12), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(counter), (345, 40), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "        \n",
    "        cv2.imshow(\"CV2\", image)\n",
    "        \n",
    "        # Press Q to close cv2 window\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # (Optional)Fix bugs cannot close windows in MacOS (https://stackoverflow.com/questions/6116564/destroywindow-does-not-close-window-on-mac-using-python-and-opencv)\n",
    "    for i in range (1, 5):\n",
    "        cv2.waitKey(1)\n",
    "  "
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 22:24:52.349 python[34933:24684623] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "2024-09-11 22:24:53.332015: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9260f401923fb5c4108c543a7d176de9733d378b3752e49535ad7c43c2271b65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
